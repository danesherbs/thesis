\addcontentsline{toc}{chapter}{Abstract}

\begin{abstract}

Reinforcement learning has achieved considerable success in recent years. One significant breakthrough was Google DeepMind's deep Q-network (DQN), which mastered a wide range of Atari 2600 games to a super-human level using only the pixels and score. However, reinforcement learning agents lack essential properties necessary for artificial general intelligence (AGI); namely they are slow to learn, unable to transfer knowledge between similar tasks and are unable to reason abstractly. The recent invention of deep symbolic reinforcement learning (DSRL), which is a marrying of deep reinforcement learning and symbolic logic, is a promising approach to overcome these drawbacks. However, this framework relies on the use of variational autoencoders to extract objects and their position in an unsupervised manner, which is currently an open problem in AI research. In this project, we pair a recent development of a scalable unsupervised method of learning generative factors in complex scenes, known as $\beta$-VAE, to fully-convolutional variational autoencoders in an attempt to preserve the spatial information necessary for DSRL.

TODO: Finish

\end{abstract}