\relax 
\@writefile{toc}{\contentsline {chapter}{Acknowledgements}{i}}
\citation{Rosen2012}
\citation{Ormerod2016}
\citation{Garnelo2016}
\citation{Knight2016}
\citation{Darrach}
\citation{Reingold2001}
\citation{Garnelo2016}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Motivation}{1}}
\citation{Hutter2005}
\citation{Mnih2015}
\citation{Silver2016}
\citation{Rosen2012}
\citation{Rosen2012}
\citation{Ormerod2016}
\citation{Ormerod2016}
\citation{Garnelo2016}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces May 1997: Gary Kasparov makes his first move against IBM's Deep Blue. Deep Blue would later emerge the victor in the best of six games; the first time a reigning world chess champion is defeated by a computer. \cite  {Rosen2012}\relax }}{2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:deep_blue_kasparov}{{1.1}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces March 2016: Lee Sedol, one of the greatest modern Go players, plays his first move of game three against AlphaGo. AlphaGo won four of five games. This feat was considered by many to be a decade away. \cite  {Ormerod2016}\relax }}{2}}
\newlabel{fig:alpha_go_first_move_game_three}{{1.2}{2}}
\citation{Garnelo2016}
\citation{Garnelo2016}
\citation{Garnelo2016}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Overview of deep symbolic reinforcement learning system architecture. \textbf  {A}: The neural back end maps high-dimensional raw input data to a compositionally structured symbolic representation. \textbf  {B}: The compositionally structured symbolic representation. \textbf  {C}: Reinforcement learning of mapping from symbolic representation to action with maximum expected reward over time. \textit  {Source: Garnelo et al.} \cite  {Garnelo2016}.\relax }}{4}}
\newlabel{fig:dsrl_archiecture}{{1.3}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Objectives}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces A toy example of a raw high-dimensional input.\relax }}{4}}
\newlabel{fig:dsrl_raw_input}{{1.4}{4}}
\newlabel{tab:dsrl_symbolic_representation}{{\caption@xref {tab:dsrl_symbolic_representation}{ on input line 84}}{5}}
\@writefile{lot}{\contentsline {table}{\numberline {1.1}{\ignorespaces Low-dimensional symbolic representation\relax }}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Contributions}{5}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background Theory}{6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:background}{{2}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Introduction}{6}}
\citation{Doersch2016}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Arithmetic in Neural Networks}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Neurons}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Activation Functions}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Convolutions}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}Deconvolutions}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.5}Pooling and Up-Sampling}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Loss functions}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Euclidean Distance}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces \relax }}{8}}
\newlabel{fig:eucledian_distance_a}{{2.1}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces \relax }}{8}}
\newlabel{fig:eucledian_distance_c}{{2.2}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces \relax }}{8}}
\newlabel{fig:eucledian_distance_b}{{2.3}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Binary Cross-Entropy}{8}}
\citation{Liou2008}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Autoencoders}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces A black-box description of an autoencoder. The autoencoder learns the identity function, and in turn, the encoder and decoder learn suitable encoding and decoding algorithms respectively.\relax }}{9}}
\newlabel{fig:autoencoder_black_box_architecture}{{2.4}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Fully-Connected Autoencoders}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces An example architecture of a fully-connected autoencoder. The latent space is constrained by having fewer neurons than the input and output layers.\relax }}{10}}
\newlabel{fig:autoencoder_architecture}{{2.5}{10}}
\citation{Krizhevsky2012}
\citation{Zeiler2014}
\citation{Szegedy2015}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces A simple fully-connected autoencoder with one hidden layer. After 15 epochs, the validation score was recorded to be $71.94$.\relax }}{11}}
\newlabel{tab:fully_connected_autoencoder_architecture}{{2.1}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Fully-Convolutional Autoencoders}{11}}
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces A simple fully-convolutional autoencoder with 2D convolutions and max pooling, plus the corresponding deconvolutional layers. After 15 epochs, the validation score was recorded to be $64.89$.\relax }}{11}}
\newlabel{tab:convolutional_autoencoder_architecture}{{2.2}{11}}
\citation{Doersch2016}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}Variational Autoencoders}{12}}
\@writefile{toc}{\contentsline {subsubsection}{Introduction}{12}}
\@writefile{toc}{\contentsline {subsubsection}{Probabilistic Perspective}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces A collection of images from the MNIST data set and their respective reconstructions using the fully-connected autoencoder specified in Table 2.1\hbox {}. The original MNIST images are in odd columns, and their reconstructions to their immediate right.\relax }}{14}}
\newlabel{fig:fully_connected_autoencoder_mnist}{{2.6}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces A collection of images from the MNIST data set and their respective reconstructions using the fully-convolutional autoencoder specified in Table 2.2\hbox {}. The original MNIST images are in odd columns, and their reconstructions to their immediate right.\relax }}{15}}
\newlabel{fig:convolutional_autoencoder_mnist}{{2.7}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces An example architecture of a fully-convolutional autoencoder. The latent space is constrained by reducing the number and/or size of the filters.\relax }}{16}}
\newlabel{fig:convolutional_autoencoder_architecture}{{2.8}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces An example architecture of a fully-convolutional autoencoder. The latent space is constrained by reducing the number and/or size of the filters.\relax }}{16}}
\newlabel{fig:variational_autoencoder_plate_model}{{2.9}{16}}
\bibstyle{abbrv}
\bibdata{library}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Conclusion}{17}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:conclusions}{{3}{17}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Summary of Thesis Achievements}{17}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Applications}{17}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Future Work}{17}}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{17}}
\bibcite{Darrach}{1}
\bibcite{Doersch2016}{2}
\bibcite{Garnelo2016}{3}
\bibcite{Hutter2005}{4}
\bibcite{Knight2016}{5}
\bibcite{Krizhevsky2012}{6}
\bibcite{Liou2008}{7}
\bibcite{Mnih2015}{8}
\bibcite{Ormerod2016}{9}
\bibcite{Reingold2001}{10}
\bibcite{Rosen2012}{11}
\bibcite{Silver2016}{12}
\bibcite{Szegedy2015}{13}
\bibcite{Zeiler2014}{14}
