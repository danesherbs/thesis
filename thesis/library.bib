Automatically generated by Mendeley Desktop 1.17.9
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@misc{Chollet2015,
abstract = {Deep Learning library for Python. Convnets, recurrent neural networks, and more. Runs on Theano or TensorFlow.},
author = {Chollet, Fran{\c{c}}ois},
booktitle = {GitHub Repository},
title = {{Keras: Deep Learning library for Theano and TensorFlow}},
year = {2015}
}
@inproceedings{Hinton2011,
abstract = {The artificial neural networks that are used to recognise shapes typcially use one or more layers of learned feature detectors that produce scalar outputs. By contrast, the computer vision community uses complicated, hand-engineered representations of the pose of the feature, like SIFT, that produce a whole vector of outputs including an explicit representation of the pose of the feature. We show how neural networks can be used to learn features that output a whole vector of instatiation parameters and we argue that this is a much more promising way of dealing with variations in position, orientation, scale and lighting than the methods currently employed in the neural networks community. It is also more promising than the hand-engineered features currently used in computer vision because it provides an efficient way of adpating the features to the domain},
archivePrefix = {arXiv},
arxivId = {cs/9605103},
author = {Hinton, Geoffrey E. and Krizhevsky, Alex and Wang, Sida D.},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-642-21735-7_6},
eprint = {9605103},
isbn = {9783642217340},
issn = {03029743},
keywords = {Invariance,auto-encoder,shape representation},
number = {PART 1},
pages = {44--51},
pmid = {1000183096},
primaryClass = {cs},
title = {{Transforming auto-encoders}},
volume = {6791 LNCS},
year = {2011}
}
@book{Hutter2005,
abstract = {This book presents sequential decision theory from a novel algorithmic information theory perspective. While the former is suited for active agents in known environments, the latter is suited for passive prediction in unknown environments. The book introduces these two different ideas and removes the limitations by unifying them to one parameter-free theory of an optimal reinforcement learning agent embedded in an unknown environment. Most AI problems can easily be formulated within this theory, reducing the conceptual problems to pure computational ones. Considered problem classes include sequence prediction, strategic games, function minimization, reinforcement and supervised learning. The discussion includes formal definitions of intelligence order relations, the horizon problem and relations to other approaches. One intention of this book is to excite a broader AI audience about abstract algorithmic information theory concepts, and conversely to inform theorists about exciting applications to AI.},
archivePrefix = {arXiv},
arxivId = {1202.6153},
author = {Hutter, Marcus},
booktitle = {Machine Learning},
doi = {10.1145/1358628.1358961},
eprint = {1202.6153},
isbn = {9783540221395},
keywords = {Artificial intelligence,Bayes mixture distributions,Kolmogorov complexity,Levin search,Solomonoff induction,algorithmic probability,function minimization,reinforcement learning,sequential decision theory,strategic games,supervised learning.,tight loss and error bounds,universal sequence prediction},
number = {2},
pages = {1--82},
pmid = {20949757},
title = {{Universal Artificial Intelligence}},
url = {http://books.google.com/books?id=NP53iZGt4KUC{\&}pg=PA255{\&}dq=Hutter+(2004+Universal+AI){\&}ie=ISO-8859-1{\&}cd=1{\&}source=gbs{\_}api},
volume = {1},
year = {2005}
}
@article{Whitney2016,
abstract = {We introduce a neural network architecture and a learning algorithm to produce factorized symbolic representations. We propose to learn these concepts by observing consecutive frames, letting all the components of the hidden representation except a small discrete set (gating units) be predicted from the previous frame, and let the factors of variation in the next frame be represented entirely by these discrete gated units (corresponding to symbolic representations). We demonstrate the efficacy of our approach on datasets of faces undergoing 3D transformations and Atari 2600 games.},
archivePrefix = {arXiv},
arxivId = {1602.06822},
author = {Whitney, William F and Chang, Michael and Kulkarni, Tejas and Tenenbaum, Joshua B},
eprint = {1602.06822},
journal = {arXiv},
pages = {1--4},
title = {{Understanding Visual Concepts with Continuation Learning}},
url = {http://arxiv.org/abs/1602.06822},
year = {2016}
}
@article{Kingma2014,
abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
archivePrefix = {arXiv},
arxivId = {1312.6114},
author = {Kingma, Diederik P and Welling, Max},
doi = {10.1051/0004-6361/201527329},
eprint = {1312.6114},
isbn = {1312.6114v10},
issn = {1312.6114v10},
journal = {Iclr},
number = {Ml},
pages = {1--14},
title = {{Auto-Encoding Variational Bayes}},
url = {http://arxiv.org/abs/1312.6114},
year = {2014}
}
@article{Rippel2013,
abstract = {One of the fundamental problems in machine learning is the estimation of a probability distribution from data. Many techniques have been proposed to study the structure of data, most often building around the assumption that observations lie on a lower-dimensional manifold of high probability. It has been more difficult, however, to exploit this insight to build explicit, tractable density models for high-dimensional data. In this paper, we introduce the deep density model (DDM), a new approach to density estimation. We exploit insights from deep learning to construct a bijective map to a representation space, under which the transformation of the distribution of the data is approximately factorized and has identical and known marginal densities. The simplicity of the latent distribution under the model allows us to feasibly explore it, and the invertibility of the map to characterize contraction of measure across it. This enables us to compute normalized densities for out-of-sample data. This combination of tractability and flexibility allows us to tackle a variety of probabilistic tasks on high-dimensional datasets, including: rapid computation of normalized densities at test-time without evaluating a partition function; generation of samples without MCMC; and characterization of the joint entropy of the data.},
archivePrefix = {arXiv},
arxivId = {1302.5125},
author = {Rippel, Oren and Adams, Ryan Prescott},
doi = {abs/1302.5125},
eprint = {1302.5125},
journal = {arXiv:1410.8516},
pages = {12},
title = {{High-Dimensional Probability Estimation with Deep Density Models}},
url = {http://arxiv.org/abs/1302.5125},
year = {2013}
}
@article{Chen2016,
abstract = {This paper describes InfoGAN, an information-theoretic extension to the Generative Adversarial Network that is able to learn disentangled representations in a completely unsupervised manner. InfoGAN is a generative adversarial network that also maximizes the mutual information between a small subset of the latent variables and the observation. We derive a lower bound to the mutual information objective that can be optimized efficiently, and show that our training procedure can be interpreted as a variation of the Wake-Sleep algorithm. Specifically, InfoGAN successfully disentangles writing styles from digit shapes on the MNIST dataset, pose from lighting of 3D rendered images, and background digits from the central digit on the SVHN dataset. It also discovers visual concepts that include hair styles, presence/absence of eyeglasses, and emotions on the CelebA face dataset. Experiments show that InfoGAN learns interpretable representations that are competitive with representations learned by existing fully supervised methods.},
archivePrefix = {arXiv},
arxivId = {1606.03657},
author = {Chen, Xi and Duan, Yan and Houthooft, Rein and Schulman, John and Sutskever, Ilya and Abbeel, Pieter},
eprint = {1606.03657},
journal = {arXiv:1606.03657 [cs.LG]},
pages = {1--14},
title = {{InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets}},
url = {http://arxiv.org/abs/1606.03657},
year = {2016}
}
@article{Thiagarajan2016,
abstract = {Learning an interpretable factorised representation of the independent data gen-erative factors of the world without supervision is an important precursor for the development of artificial intelligence that is able to learn and reason in the same way that humans do. We introduce $\beta$-VAE, a new state-of-the-art framework for automated discovery of interpretable factorised latent representations from raw image data in a completely unsupervised manner. Our approach is a modification of the variational autoencoder (VAE) framework. We introduce an adjustable hy-perparameter $\beta$ that balances latent channel capacity and independence constraints with reconstruction accuracy. We demonstrate that $\beta$-VAE with appropriately tuned $\beta$ {\textgreater} 1 qualitatively outperforms VAE ($\beta$ = 1), as well as state of the art unsu-pervised (InfoGAN) and semi-supervised (DC-IGN) approaches to disentangled factor learning on a variety of datasets (celebA, faces and chairs). Furthermore, we devise a protocol to quantitatively compare the degree of disentanglement learnt by different models, and show that our approach also significantly outperforms all baselines quantitatively. Unlike InfoGAN, $\beta$-VAE is stable to train, makes few assumptions about the data and relies on tuning a single hyperparameter $\beta$, which can be directly optimised through a hyperparameter search using weakly labelled data or through heuristic visual inspection for purely unsupervised data.},
author = {Thiagarajan, By Ganesh and Member, Associate and Voyiadjis, George Z},
journal = {ICLR'17 submission},
number = {July},
pages = {1--13},
title = {{beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework}},
year = {2016}
}
@article{Krizhevsky2011,
abstract = {We show how to learn many layers of features on color images and we use these features to initialize deep autoencoders. We then use the autoencoders to map images to short binary codes. Using semantic hashing [6], 28-bit codes can be used to retrieve images that are similar to a query image in a time that is independent of the size of the database. This extremely fast retrieval makes it possible to search using multiple dierent transformations of the query image. 256-bit binary codes allow much more accurate matching and can be used to prune the set of images found using the 28-bit codes.},
author = {Krizhevsky, Alex and Hinton, Ge},
isbn = {9782874190445},
journal = {Proceedings of the European Symposium on Artificial Neural Networks (ESANN)},
pages = {1--7},
title = {{Using Very Deep Autoencoders for Content-Based Image Retrieval}},
year = {2011}
}
@misc{Chollet2016,
abstract = {In this tutorial, we will answer some common questions about autoencoders, and we will cover code examples of the models...},
author = {Chollet, Fran{\c{c}}ois},
booktitle = {The Keras Blog},
pages = {1--14},
title = {{Building Autoencoders in Keras}},
year = {2016}
}
@article{Torrey2009,
abstract = {In the drug discovery process, the metabolic fate of drugs is crucially important to prevent drug-drug interactions. Therefore, P450 isozyme selectivity prediction is an important task for screening drugs of appropriate metabolism profiles. Recently, large-scale activity data of five P450 isozymes (CYP1A2 CYP2C9, CYP3A4, CYP2D6, and CYP2C19) have been obtained using quantitative high-throughput screening with a bioluminescence assay. Although some isozymes share similar selectivities, conventional supervised learning algorithms independently learn a prediction model from each P450 isozyme. They are unable to exploit the other P450 isozyme activity data to improve the predictive performance of each P450 isozyme's selectivity. To address this issue, we apply transfer learning that uses activity data of the other isozymes to learn a prediction model from multiple P450 isozymes. After using the large-scale P450 isozyme selectivity dataset for five P450 isozymes, we evaluate the model's predictive performance. Experimental results show that, overall, our algorithm outperforms conventional supervised learning algorithms such as support vector machine (SVM), Weighted k-nearest neighbor classifier, Bagging, Adaboost, and latent semantic indexing (LSI). Moreover, our results show that the predictive performance of our algorithm is improved by exploiting the multiple P450 isozyme activity data in the learning process. Our algorithm can be an effective tool for P450 selectivity prediction for new chemical entities using multiple P450 isozyme activity data.},
author = {Torrey, Lisa and Shavlik, Jude},
doi = {10.1016/j.jbi.2011.04.009},
isbn = {9781605667669},
issn = {0219-7200},
journal = {Machine Learning},
pages = {1--22},
pmid = {21776607},
title = {{Transfer Learning}},
year = {2009}
}
@article{Doersch2016,
abstract = {In just three years, Variational Autoencoders (VAEs) have emerged as one of the most popular approaches to unsupervised learning of complicated distributions. VAEs are appealing because they are built on top of standard function approximators (neural networks), and can be trained with stochastic gradient descent. VAEs have already shown promise in generating many kinds of complicated data, including handwritten digits, faces, house numbers, CIFAR images, physical models of scenes, segmentation, and predicting the future from static images. This tutorial introduces the intuitions behind VAEs, explains the mathematics behind them, and describes some empirical behavior. No prior knowledge of variational Bayesian methods is assumed.},
archivePrefix = {arXiv},
arxivId = {1606.05908},
author = {Doersch, Carl},
eprint = {1606.05908},
journal = {arXiv},
keywords = {neural networks,prediction,structured,unsupervised learning,variational autoencoders},
pages = {1--23},
title = {{Tutorial on Variational Autoencoders}},
url = {http://arxiv.org/abs/1606.05908},
year = {2016}
}
@misc{Pimentel2014,
abstract = {Novelty detection is the task of classifying test data that differ in some respect from the data that are available during training. This may be seen as "one-class classification", in which a model is constructed to describe "normal" training data. The novelty detection approach is typically used when the quantity of available "abnormal" data is insufficient to construct explicit models for non-normal classes. Application includes inference in datasets from critical systems, where the quantity of available normal data is very large, such that "normality" may be accurately modelled. In this review we aim to provide an updated and structured investigation of novelty detection research papers that have appeared in the machine learning literature during the last decade. ?? 2014 Published by Elsevier B.V.},
author = {Pimentel, Marco A F and Clifton, David A. and Clifton, Lei and Tarassenko, Lionel},
booktitle = {Signal Processing},
doi = {10.1016/j.sigpro.2013.12.026},
isbn = {0165-1684},
issn = {01651684},
keywords = {Machine learning,Novelty detection,One-class classification},
pages = {215--249},
title = {{A review of novelty detection}},
volume = {99},
year = {2014}
}
@article{Garnelo2016,
abstract = {Deep reinforcement learning (DRL) brings the power of deep neural networks to bear on the generic task of trial-and-error learning, and its effectiveness has been convincingly demonstrated on tasks such as Atari video games and the game of Go. However, contemporary DRL systems inherit a number of shortcomings from the current generation of deep learning techniques. For example, they require very large datasets to work effectively, entailing that they are slow to learn even when such datasets are available. Moreover, they lack the ability to reason on an abstract level, which makes it difficult to implement high-level cognitive functions such as transfer learning, analogical reasoning, and hypothesis-based reasoning. Finally, their operation is largely opaque to humans, rendering them unsuitable for domains in which verifiability is important. In this paper, we propose an end-to-end reinforcement learning architecture comprising a neural back end and a symbolic front end with the potential to overcome each of these shortcomings. As proof-of-concept, we present a preliminary implementation of the architecture and apply it to several variants of a simple video game. We show that the resulting system -- though just a prototype -- learns effectively, and, by acquiring a set of symbolic rules that are easily comprehensible to humans, dramatically outperforms a conventional, fully neural DRL system on a stochastic variant of the game.},
archivePrefix = {arXiv},
arxivId = {1609.05518},
author = {Garnelo, Marta and Arulkumaran, Kai and Shanahan, Murray},
eprint = {1609.05518},
journal = {arXiv Preprint},
pages = {1--13},
title = {{Towards Deep Symbolic Reinforcement Learning}},
url = {http://arxiv.org/abs/1609.05518},
year = {2016}
}
@article{Higgins2016,
abstract = {Automated discovery of early visual concepts from raw image data is a major open challenge in AI research. Addressing this problem, we propose an unsupervised approach for learning disentangled representations of the underlying factors of variation. We draw inspiration from neuroscience, and show how this can be achieved in an unsupervised generative model by applying the same learning pressures as have been suggested to act in the ventral visual stream in the brain. By enforcing redundancy reduction, encouraging statistical independence, and exposure to data with transform continuities analogous to those to which human infants are exposed, we obtain a variational autoencoder (VAE) framework capable of learning disentangled factors. Our approach makes few assumptions and works well across a wide variety of datasets. Furthermore, our solution has useful emergent properties, such as zero-shot inference and an intuitive understanding of "objectness".},
archivePrefix = {arXiv},
arxivId = {1606.05579},
author = {Higgins, Irina and Matthey, Loic and Glorot, Xavier and Pal, Arka and Uria, Benigno and Blundell, Charles and Mohamed, Shakir and Lerchner, Alexander},
eprint = {1606.05579},
journal = {arXiv},
title = {{Early Visual Concept Learning with Unsupervised Deep Learning}},
url = {http://arxiv.org/abs/1606.05579},
year = {2016}
}
@article{Bengio2013,
abstract = {The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, autoencoders, manifold learning, and deep networks. This motivates longer term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation, and manifold learning.},
archivePrefix = {arXiv},
arxivId = {arXiv:1206.5538v2},
author = {Bengio, Y and Courville, A and Vincent, P},
doi = {10.1109/TPAMI.2013.50},
eprint = {arXiv:1206.5538v2},
isbn = {0162-8828},
issn = {1939-3539},
journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
keywords = {AI,Abstracts,Boltzmann machine,Deep learning,Feature extraction,Learning systems,Machine learning,Manifolds,Neural networks,Speech recognition,artificial intelligence,autoencoder,autoencoders,data representation,data structures,density estimation,feature learning,geometrical connections,machine learning algorithms,manifold learning,neural nets,probabilistic models,probability,representation learning,unsupervised feature learning,unsupervised learning},
number = {8},
pages = {1798--1828},
pmid = {23787338},
title = {{Representation Learning: A Review and New Perspectives}},
volume = {35},
year = {2013}
}
@inproceedings{Bellemare2015,
abstract = {In this article we introduce the Arcade Learning Environment (ALE): both a challenge problem and a platform and methodology for evaluating the development of general, domain-independent AI technology. ALE provides an interface to hundreds of Atari 2600 game environments, each one different, interesting, and designed to be a challenge for human players. ALE presents significant research challenges for reinforcement learning, model learning, model-based planning, imitation learning, transfer learning, and intrinsic motivation. Most importantly, it provides a rigorous testbed for evaluating and comparing approaches to these problems. We illustrate the promise of ALE by developing and benchmarking domain-independent agents designed using well-established AI techniques for both reinforcement learning and planning. In doing so, we also propose an evaluation methodology made possible by ALE, reporting empirical results on over 55 different games. All of the software, including the benchmark agents, is publicly available.},
archivePrefix = {arXiv},
arxivId = {1207.4708},
author = {Bellemare, Marc G. and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
booktitle = {IJCAI International Joint Conference on Artificial Intelligence},
doi = {10.1613/jair.3912},
eprint = {1207.4708},
isbn = {9781577357384},
issn = {10450823},
pages = {4148--4152},
title = {{The arcade learning environment: An evaluation platform for general agents}},
volume = {2015-Janua},
year = {2015}
}
@article{Lake2016,
abstract = {Recent progress in artificial intelligence (AI) has renewed interest in building systems that learn and think like people. Many advances have come from using deep neural networks trained end-to-end in tasks such as object recognition, video games, and board games, achieving perfor- mance that equals or even beats humans in some respects. Despite their biological inspiration and performance achievements, these systems differ from human intelligence in crucial ways. We review progress in cognitive science suggesting that truly human-like learning and thinking machines will have to reach beyond current engineering trends in both what they learn, and how they learn it. Specifically, we argue that these machines should (a) build causal models of the world that support explanation and understanding, rather than merely solving pattern recog- nition problems; (b) ground learning in intuitive theories of physics and psychology, to support and enrich the knowledge that is learned; and (c) harness compositionality and learning-to-learn to rapidly acquire and generalize knowledge to new tasks and situations. We suggest concrete challenges and promising routes towards these goals that can combine the strengths of recent neural network advances with more structured cognitive models.},
archivePrefix = {arXiv},
arxivId = {1604.00289},
author = {Lake, Brenden M. and Ullman, Tomer D. and Tenenbaum, Joshua B. and Gershman, Samuel J.},
doi = {1511.09249v1},
eprint = {1604.00289},
issn = {14691825},
journal = {arXiv:1604.00289v1[cs.AI]},
pages = {1--54},
pmid = {1000303116},
title = {{Building Machines that learn and think like people}},
url = {https://arxiv.org/pdf/1604.00289v1.pdf},
year = {2016}
}
@article{Dumoulin2016,
abstract = {We introduce a guide to help deep learning practitioners understand and manipulate convolutional neural network architectures. The guide clarifies the relationship between various properties (input shape, kernel shape, zero padding, strides and output shape) of convolutional, pooling and transposed convolutional layers, as well as the relationship between convolutional and transposed convolutional layers. Relationships are derived for various cases, and are illustrated in order to make them intuitive.},
archivePrefix = {arXiv},
arxivId = {1603.07285},
author = {Dumoulin, Vincent and Visin, Francesco},
doi = {10.1051/0004-6361/201527329},
eprint = {1603.07285},
isbn = {9783319105895},
issn = {16113349},
journal = {Arxiv},
pages = {1--28},
pmid = {26353135},
title = {{A guide to convolution arithmetic for deep learning}},
url = {http://arxiv.org/abs/1603.07285},
year = {2016}
}
@article{Reed2014,
abstract = {Many latent factors of variation interact to generate sensory data; for example pose, morphology and expression in face images. We propose to learn manifold coordinates for the relevant factors of variation and to model their joint interaction. Most existing feature learning algorithms focus on a single task and extract features that are sensitive to the task-relevant factors and invariant to all others. However, models that just extract a single set of invariant features do not exploit the relationships among the latent factors. To address this we propose a higher-order Boltzmann machine that incorporates multiplicative interactions among groups of hidden units that each learn to encode a factor of variation. Furthermore, we propose a manifold-based training strategy that allows effective disentangling, meaning that units in each group encode a distinct type of variation. Our model achieves state-of-the-art emotion recognition and face verification performance on the Toronto Face Database, and we also demonstrate disentangled features learned on the CMU Multi-PIE dataset.},
author = {Reed, Scott and Sohn, Kihyuk and Zhang, Yuting and Lee, Honglak},
isbn = {9781634393973},
journal = {Proceedings of the 31st International Conference on Machine Learning (ICML-14)},
number = {May},
pages = {1431--1439},
title = {{Learning to Disentangle Factors of Variation with Manifold Interaction}},
url = {http://machinelearning.wustl.edu/mlpapers/papers/icml2014c2{\_}reed14},
year = {2014}
}
@article{Ji2013,
abstract = {We consider the automated recognition of human actions in surveillance videos. Most current methods build classifiers based on complex handcrafted features computed from the raw inputs. Convolutional neural networks (CNNs) are a type of deep model that can act directly on the raw inputs. However, such models are currently limited to handling 2D inputs. In this paper, we develop a novel 3D CNN model for action recognition. This model extracts features from both the spatial and the temporal dimensions by performing 3D convolutions, thereby capturing the motion information encoded in multiple adjacent frames. The developed model generates multiple channels of information from the input frames, and the final feature representation combines information from all channels. To further boost the performance, we propose regularizing the outputs with high-level features and combining the predictions of a variety of different models. We apply the developed models to recognize human actions in the real-world environment of airport surveillance videos, and they achieve superior performance in comparison to baseline methods.},
author = {Ji, Shuiwang and Yang, Ming and Yu, Kai and Xu, Wei},
doi = {10.1109/TPAMI.2012.59},
isbn = {9781605589077},
issn = {1939-3539},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Automated,Automated: methods,Computer-Assisted,Computer-Assisted: methods,Decision Support Techniques,Image Interpretation,Imaging,Movement,Movement: physiology,Neural Networks (Computer),Pattern Recognition,Subtraction Technique,Three-Dimensional,Three-Dimensional: methods},
number = {1},
pages = {221--31},
pmid = {22392705},
title = {{3D convolutional neural networks for human action recognition}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6165309{\%}5Cnhttp://www.ncbi.nlm.nih.gov/pubmed/22392705},
volume = {35},
year = {2013}
}
@article{IanGoodfellowYoshuaBengio2015,
abstract = {Deep learning draws upon many modeling formalisms that researchers can use to guide their design efforts and describe their algorithms. One of these formalisms is the idea of structured probabilistic models. We have already discussed structured probabilistic models briefly in Chapter 3.14. That brief presentation was sufficient to understand how to use structured probabilistic models as a language to describe some of the algorithms in part II of this book. Now, in part III, structured probabilistic models are a key ingredient of many of the most important research topics in deep learning. In order to prepare to discuss these research ideas, this chapter describes structured probabilistic models in much greater detail. This chapter is intended to be self-contained; the reader does not need to review the earlier introduction before continuing with this chapter. A structured probabilistic model is a way of describing a probability distribu-tion, using a graph to describe which random variables in the probability distri-bution interact with each other directly. Here we use " graph " in the graph theory senseâ€“a set of vertices connected to one another by a set of edges. Because the structure of the model is defined by a graph, these models are often also referred to as graphical models. The graphical models research community is large and has developed many different models, training algorithms, and inference algorithms. In this chap-ter, we provide basic background on some of the most central ideas of graphical models, with an emphasis on the concepts that have proven most useful to the deep learning research community. If you already have a strong background in graphical models, you may wish to skip most of this chapter. However, even a graphical model expert may benefit from reading the final section of this chap-ter, section 13.6, in which we highlight some of the unique ways that graphical 412 CHAPTER 13. STRUCTURED PROBABILISTIC MODELS FOR DEEP LEARNING models are used for deep learning algorithms. Deep learning practitioners tend to use very different model structures, learning algorithms, and inference procedures than are commonly used by the rest of the graphical models research community. In this chapter, we identify these differences in preferences and explain the reasons for them. In this chapter we first describe the challenges of building large-scale proba-bilistic models in section 13.1. Next, we describe how to use a graph to describe the structure of a probability distribution in section 13.2. We then revisit the challenges we described in section 13.1 and show how the structured approach to probabilistic modeling can overcome these challenges in section 13.3. One of the major difficulties in graphical modeling is understanding which variables need to be able to interact directly, i.e., which graph structures are most suitable for a given problem. We outline two approaches to resolving this difficulty by learning about the dependencies in section 13.4. Finally, we close with a discussion of the unique emphasis that deep learning practitioners place on specific approaches to graphical modeling in section 13.6. 13.1 The Challenge of Unstructured Modeling},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {{Ian Goodfellow, Yoshua Bengio}, Aaron Courville},
doi = {10.1016/B978-0-12-391420-0.09987-X},
eprint = {arXiv:1011.1669v3},
isbn = {3540620583, 9783540620587},
issn = {1437-7780},
journal = {Deep Learning},
keywords = {machine learning},
number = {1},
pages = {111--124},
pmid = {21728107},
title = {{Deep Learning Book}},
url = {http://www.deeplearningbook.org/},
volume = {21},
year = {2015}
}
