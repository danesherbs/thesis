\documentclass[12pt,twoside]{article}

\newcommand{\reporttitle}{Project Interim Report}
\newcommand{\reportauthor}{Dane G. Sherburn}
\newcommand{\reporttype}{Project III}
\newcommand{\cid}{00820119}

% include files that load packages and define macros
\input{includes} % various packages needed for maths etc.
\input{notation} % short-hand notation and macros

%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

% front page
\input{titlepage}

% table of contents
\tableofcontents
\newpage

% bibliography style
\bibliographystyle{unsrt} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%% Main document
\section{Introduction}
A long term goal of artificial intelligence (AI) is the development of artificial general intelligence (AGI). A number of theoretical frameworks have been presented to formalize what it means to achieve AGI, notably by \cite{Hutter2005}.\\

Reinforcement learning is fundamental in this framework. It's therefore quite exciting that deep reinforcement learning (DRL) systems have recently been able to master a wide range of tasks, including Atari games and Go. Though DRL systems have been remarkably successful, they still have a number of drawbacks \cite{Garnelo2016} \cite{Chollet2015}:

\begin{enumerate}
\item \textbf{Slow to learn}. Deep neural networks require large data sets and are therefore slow to learn.
\item \textbf{Fail to transfer past experience}. They often fail to perform well on tasks very similar to those they have mastered.
\item \textbf{Inability to reason abstractly.} They fail to exploit statistical regularities in the training data by using high-level processes like planning or causal reasoning.
\item \textbf{Hard to reason about.} It's often troublesome to understand why the DRL system chose the action it did.
\end{enumerate}

Deep symbolic reinforcement learning (DSRL) is a recent advance which seeks to overcome all of these drawbacks at once without the drawbacks from classical symbolic AI, namely the symbol grounding problem \cite{Garnelo2016}.\\

This novel architecture relies on the representation of its input data to facilitate conceptual abstraction, allowing for transfer learning and high-level cognitive processes. Low-dimensional representations where single latent \cite{Garnelo2016}. However, the unsupervised extraction of features from a wide range of scenes is still a challenge in AI research \cite{Bengio2013}.\\

The aim of this project is to investigate compositional representations and evaluate their effectiveness in deep symbolic reinforcement systems. We plan to achieve this as follows:

\begin{enumerate}
\item Implement many flavours of autoencoders, including mixing and matchings of standard, convolutional and variational autoencoders, and investigate the relationship between the latent space and their final reconstructions. This will hopefully convey some intuition about the way scenes are typically represented in the latent space, their relevance in transfer learning and the significance of the problem we're trying to solve.
\item Next we focus our attention on convolutional variational autoencoders. We'll try to encourage the latent space to assume a compositional structure by tuning a hyperparameter $\beta$ in a $\beta$-VAE (to be introduced in Chapter X) through heuristic visual inspection. All experiments will be on a range of Atari 2600 games using the Atari Learning Environment.
\item Finally we can evaluate the value of a compositional structured latent space in a deep symbolic reinforcement system. We'll do this by exploring how well the compositional representation embodies common sense priors, such as object persistence and causality. We will also assess its ability to facilitate high-level cognitive processes, such as transfer learning and look-ahead.
\end{enumerate}

\section{Background}
The background section of the report should set the project into context by relating it to existing published work which you read at the start of the project when your approach and methods were being considered. There are usually many ways of solving a given problem, and you shouldn't just pick one at random. Describe and evaluate as many alternative approaches as possible. The published work may be in the form of research papers, articles, text books, technical manuals, or even existing software or hardware of which you have had hands-on experience.

Why we chose this approach (refer to lots of papers that offer alternatives. Why did you pick this one?)\\

This chapter will contain the material necessary to understand later chapters and provide the context for our contributions in Chapter X.\\

We will introduce deep symbolic reinforcement learning which will motivate our interest in unsupervised disentangled representations. Here we'll explore state-of-the-art approaches to finding such representations, which will also require a brief introduction to autoencoders. Finally we'll mention less theoretical matters, including libraries used and the Arcade Learning Environment.

% Autoencoders
\subsection{Autoencoders}

\subsubsection{Architecture}

\subsubsection{Convolutional autoencoders}

\subsubsection{Variational autoencoders}

The autoencoders we've seen so far do the following: given input $\vec{x}$, compute its reconstruction $\widetilde{\vec{x}}$, after mapping it to a lower dimensional vector $\vec{z}$, the \textit{latent space}. The aim of the variational autoencoder (VAE) is quite similar: given input samples from an unknown distribution $p(\vec{x})$, generate $\widetilde{\vec{x}}$ very similar to those in $p(\vec{x})$, after sampling a lower-dimensional vector $\vec{z}$. Since VAEs generate unseen, similar samples, they are \textit{generative models} \cite{Doersch2016}.\\

To justify the statements in the next paragraph, we have to mention that $p_{\theta}(\vec{z}|\vec{x})=\frac{p(\vec{x}|\vec{z})p(\vec{z})}{p(\vec{x})}$ is intractable due to the marginal likelihood $p(\vec{x})$ being exponentially computationally expensive, motivating the introduction of the probabilistic encoder $q_{\phi}(\vec{z}|\vec{x})$ to approximate the posterior $p_{\theta}(\vec{z}|\vec{x})$. Since $q_{\phi}(\vec{z}|\vec{x})$ appears in the loss function but is not differentiable (we can't differentiate random variables), we need to use the \textit{reparameterisation trick}. The reparameterisation trick expresses $\vec{z}\sim q_{\phi}(\vec{z}|\vec{x})$ as a deterministic variable $\vec{z}=g_{\phi}(\vec{\epsilon},\vec{x})$ where $\vec{\epsilon}$ is an auxilary variable with independent maginal and $g_{\phi}$ is a deterministic vector function parameterized by $\phi$ \cite{Kingma2014}.\\

Learning the optimal $\vec{\phi}$ and $\vec{\theta}$ is formally expressed as the following objective:
\begin{equation}
\label{vae_objective}
\max_{\vec{\phi},\vec{\theta}}\mathbf{E}_{q_{\phi}(\vec{z}|\vec{x})}[log p_{\theta}(\vec{x}|\vec{z})] - \mathcal{D}_{KL}[q_{\phi}(\vec{z}|\vec{x})||p_{\theta}(\vec{z})]
\end{equation}


% Deep symbolic reinforcement learning
\subsection{Deep symbolic reinforcement learning}

\subsubsection{Reinforcement learning}

\subsubsection{Symbolic artificial intelligence}

\subsubsection{Deep symbolic reinforcement learning}

% Representation learning
\subsection{Representation learning}

Suppose we were ordered to carry out the multiplication of two binary numbers, $1101_2$ and $101101_2$. Most of us would first convert these numbers to base-10 before performing the multiplication. We'd do this because the problem is significantly harder in base-2 than it is in base-10. It's therefore intuitive that a good representation is vital to the agent required to solve it \cite{IanGoodfellowYoshuaBengio2015}.\\

The subject of what makes a good representation has generated much interest in recent times. According to \cite{IanGoodfellowYoshuaBengio2015}, a good representation is simply one that makes subsequent tasks easier. 

\subsubsection{Disentangled representations}

It's been suggested by \cite{Bengio2013} that a crucial factor in what makes a good representation is how \textit{disentangled} it is. A disentangled representation is one where changes in latent factors correspond to changes in high-level factors in the output space \cite{Higgins2016}.\\

To provide some intuition of what a disentangled representation is, we'll consider an example using the Frey Face data set.\\

\begin{figure}
\includegraphics[scale=0.3]{figures/kingma_2014_4a.png}
\centering
\captionsetup{justification=centering}
\caption{A learned Frey Face manifold with two latent variables: one sensitive to the expression and one to the orientation. \cite{Kingma2014}}
\label{frey_face_disentangled}
\end{figure}

The Frey Face data set consists of almost two-thousand $28\times20$ pictures of Brendan Frey, a Canadian machine learning researcher. The samples include Frey with varying facial expressions and orientations.\\

Shown in Figure (\ref{frey_face_disentangled}) is a learned Frey Face manifold with two latent variables. One latent variable is sensitive to changes in the expression and one to changes in orientation, making the manifold a highly disentangled representation. In an entangled representation, changing one latent variable would change both the expression and the orientation.\\

Disentangled representations facilitate the reuse of previously learnt factors, called \textit{knowledge transfer}; and the extreme case, \textit{zero-shot inference} \cite{IanGoodfellowYoshuaBengio2015,Higgins2016}.

\subsubsection{Transfer learning}
Transfer learning is the reuse of learnt factors from a previous task when learning a new one \cite{IanGoodfellowYoshuaBengio2015}. If the tasks are sufficiently similar, there are three ways learning of the new task may be improved \cite{Torrey2009}:

\begin{enumerate}
\item Initial performance
\item Faster to learn
\item Final performance
\end{enumerate}

These improvements are shown on a performance-training graph in Figure \ref{transfer_learning_three_ways}.\\

\begin{figure}
\includegraphics[scale=0.3]{figures/torrey_2009_2.png}
\centering
\captionsetup{justification=centering}
\caption{An illustration of the three ways in which transfer learning may improve the learning of a new task. \cite{Torrey2009}}
\label{transfer_learning_three_ways}
\end{figure}

\begin{figure}
\includegraphics[scale=0.3]{figures/goodfellow_2015_15_2.png}
\centering
\captionsetup{justification=centering}
\caption{An illustration of how tasks may be translated into intermediate representations, then into a shared representation. The representation of different tasks in terms of common concepts is key to transfer learning. \cite{IanGoodfellowYoshuaBengio2015}}
\label{transfer_learning_graph_intuition}
\end{figure}

\begin{enumerate}
\item Summarising quote by \cite{Whitney2016} below
\end{enumerate}

"Without disentangled representations, it is difficult to interpret or re-use representations across tasks as no single component of the representation vector has a semantic meaning by itself" \cite{Whitney2016}.

\subsubsection{Zero-shot understanding}

\subsubsection{Data continuity}

\subsubsection{Statistical independence}

\subsubsection{Manifolds}

% Finding disentangled representations
\subsection{Finding disentangled representations}

\subsubsection{Supervised algorithms}

Supervised learning of disentangled representations of images.

\begin{enumerate}
\item State the some prominent supervised algorithms for learning disentangled representations
\item Show the impressive achievements of a few (particularly one with Atari Breakout)
\item Explain how this gives something to aim for in unsupervised methods
\item Explain how unless modified, these class of algorithms do not suit our purpose of end-to-end learning in DSRL.
\end{enumerate}

Some supervised methods used are:

\begin{enumerate}
\item SIFT
\item Spin image
\item HoG
\item RIFT
\item Textons
\item GLOH
\end{enumerate}

\subsubsection{Semi-supervised algorithms}

A summary of useful techniques in \cite{IanGoodfellowYoshuaBengio2015}


\subsubsection{Unsupervised algorithms}

An overview of unsupervised algorithms learning disentangled representations is given in \cite{Bengio2013}. These include deep representations, such as deep Boltzmann machines and deep belief networks, in greedy layerwise unsupervised pre-training; graphical models; autoencoders; and manifold learning. The vast majority of approaches using these techniques (and unmentioned approaches, DC-IGN and InfoGAN) assume the number of generative factors, priors and/or do not scale well. As far as we know, $\beta$-VAE is the only approach which has been shown to quantitatively outperform alternatives with respect to its ability to disentangle data, its stability in training and the relatively few assumptions about the data \cite{Higgins2016}.\\

[Perhaps more research is needed here. Do we need to look harder for more unsupervised alternatives? Is more justification for using $\beta$-VAE needed? Currently we're relying solely on the survey of unsupervised algorithms by \cite{Higgins2016}]\\

% Deeper investigation of $\beta$-VAE
\subsection{Deeper investigation of $\beta$-VAE}
\subsubsection{Framework}

Suppose we're given a set $X$ of images $\vec{x}\in\mathbb{R}^N$ and ground truth data generative factors (that is, factors observed directly from the data as opposed to being inferred). We'll partition these factors into two sets, $V$ and $W$, where vectors $\vec{v}\in\mathbb{R}^K$ are independent and $\vec{w}\in\mathbb{R}^H$ are dependent.\\

The aim of $\beta$-VAE is to factorise the latent space $\vec{z}\in\mathbb{R}^M$ into disentangled factors $\vec{v}$ and the rest. This enforces $M\geq K$, since we'd like the latent representation to be capable of learning all independent ground truth data factors of $X$.\\

$\beta$-VAE achieves this by adding an important multiplicative factor $\beta$ to the KL-divergence term, making the objective:

\begin{equation}
\label{beta_vae_objective}
\max_{\vec{\phi},\vec{\theta}}\mathbf{E}_{q_{\phi}(\vec{z}|\vec{x})}[log p_{\theta}(\vec{x}|\vec{z})] - \beta\mathcal{D}_{KL}[q_{\phi}(\vec{z}|\vec{x})||p_{\theta}(\vec{z})]
\end{equation}

The hyperparameter $\beta$ balances reconstruction error with independence constraints \cite{Higgins2016}.

\subsubsection{Disentanglement metric}
\subsubsection{Quantitative performance}
\subsubsection{Qualitative performance}

% Libraries
\subsection{Libraries}
\subsubsection{Keras}

Keras is a high-level neural network library written in Python \cite{Chollet2015} and was used to implement the frameworks in Chapter X. It was a suitable choice because it supports:

\begin{itemize}
\item Convolutional, deconvolutional and pooling layers
\item Lambda functions, which is necessary for sampling in variational autoencoders
\item Custom loss functions, which is necessary to implement the $\beta$-VAE framework
\item Able to save weights, so the same network can be trained on multiple games
\item Able to run on the GPU
\end{itemize}

\subsubsection{Arcade Learning Environment}
The Arcade Learning Environment (ALE) is a framework built on top of the Atari 2600 emulator Stella \cite{Bellemare2015}. This library was a suitable choice because:
\begin{itemize}
\item Emulation details are abstracted away from the researcher
\item The same agent can be used for all games, due to its modular design
\item Frames can be saved during game play, which is used to collect training data
\item A Python wrapper for the entire framework is provided, so our agents developed in Keras interact seamlessly
\end{itemize}

\section{Project Plan}
You should explain what needs to be done in order to complete the project and roughly what you expect the timetable to be. Don’t forget to include the project write-up (the final report), as this is a major part of the exercise. It’s important to identify key milestones and also fall-back positions, in case you run out of time.  You should also identify what extensions could be added if time permits.  The plan should be complete and should include those parts that you have already addressed (make it clear how far you have progressed at the time of writing).  This material will not appear in the final report.

\section{Evaluation plan}
Project evaluation is very important, so it's important to think now about how you plan to measure success. For example, what functionality do you need to demonstrate?  What experiments to you need to undertake and what outcome(s) would constitute success?  What benchmarks should you use? How has your project extended the state of the art?  How do you measure qualitative aspects, such as ease of use?  These are the sort of questions that your project evaluation should address; this section should outline your plan.

\bibliography{library}

\end{document}